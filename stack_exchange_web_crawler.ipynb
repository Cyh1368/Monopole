{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "\n",
    "\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import pprint\n",
    "max_chrome_driver_path = '/Users/maxlien/Downloads/chromedriver-mac-arm64/chromedriver'\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "def config():\n",
    "    load_dotenv()\n",
    "  \n",
    "config()\n",
    "\n",
    "username = str(os.getenv('MONOPLE_GMAIL'))\n",
    "password=str(os.getenv('MONOPLE_PASSWORD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackExchangeScraper:\n",
    "    def __init__(self, chrome_driver_path=max_chrome_driver_path,username=username, password=password):\n",
    "        self.driver_path = chrome_driver_path\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        #print(self.options)\n",
    "        self.service = ChromeService(executable_path=self.driver_path)\n",
    "        self.driver = webdriver.Chrome(service=self.service) #executable_path= max_chrome_driver_path)#,options=self.options)#executable_path=self.driver_path)\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "        \n",
    "        self.username =username\n",
    "        self.password = password\n",
    "\n",
    "    # ... rest of the class methods remain unchanged ...\n",
    "\n",
    "# Note: Only the initialization method of the class is shown here for brevity.\n",
    "# The rest of the class methods would remain unchanged from the previous version.\n",
    "    def _set_up_agent(self):\n",
    "        #set useragent\n",
    "        self.options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "    # def _setup_headless_driver(self):\n",
    "    #     \"\"\"\n",
    "    #     Sets up a headless Selenium Chrome driver.\n",
    "    #     \"\"\"\n",
    "    #     self.options.add_argument('--headless')\n",
    "    #     self.options.add_argument('--no-sandbox')\n",
    "    #     self.options.add_argument('--disable-dev-shm-usage')\n",
    "    #     self.driver = webdriver.Chrome(self.driver_path, options=options)\n",
    "    def _wait(self,type, name):\n",
    "        return self.wait.until(\n",
    "                EC.presence_of_element_located((type, name))\n",
    "            )\n",
    "    def _wait_all(self, type, name):\n",
    "        return self.wait.until(\n",
    "                EC.presence_of_all_elements_located((type, name))\n",
    "            )\n",
    "    def _login(self, username, password):\n",
    "        \n",
    "        \n",
    "        login_button_XPATH = '/html/body/div[1]/header[1]/div/nav/ol/li[4]/a'\n",
    "        login_button = self._wait(By.XPATH, login_button_XPATH)\n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView();\", login_button)\n",
    "        login_button.click()\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "        username_box = self._wait(By.XPATH, '//*[@id=\"email\"]')\n",
    "        username_box.send_keys(username)\n",
    "\n",
    "        password_box = self._wait(By.XPATH,'//*[@id=\"password\"]' )\n",
    "        password_box.send_keys(password)\n",
    "\n",
    "\n",
    "        submit_button =self._wait(By.XPATH, '//*[@id=\"submit-button\"]') \n",
    "        self.driver.execute_script(\"arguments[0].scrollIntoView();\", submit_button)\n",
    "        submit_button.click()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def search_links(self, input):\n",
    "        self._set_up_agent()\n",
    "        self.driver.get('https://stackexchange.com')\n",
    "\n",
    "        self._login(self.username, self.password)\n",
    "\n",
    "        search_box = self._wait(By.XPATH, '//*[@id=\"search\"]/div/input')\n",
    "        search_box.send_keys(input)\n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        \n",
    "        content = self._wait(By.CLASS_NAME, \"contentWrapper\")\n",
    "        return content\n",
    "        # try:\n",
    "        #     result_link_elements = self._wait_all(By.CLASS_NAME, \"result-link\")\n",
    "        #     #print(result_link_elements)\n",
    "        #     # Extracting the links within each of the 'result-link' elements\n",
    "        #     links = []\n",
    "        #     for element in result_link_elements:\n",
    "        #         print(element)\n",
    "        #         print(type(element))\n",
    "        #         link = element.get_attribute('href')\n",
    "        #         print(link)\n",
    "        #         links.append(link)\n",
    "        # except TimeoutException :\n",
    "        #     #maybe is redirect to meta.stackexchange\n",
    "        #     result_link_elements = self._wait_all(By.CLASS_NAME, \"s-post-summary--content-title\")\n",
    "        #     #print(result_link_elements)\n",
    "        #     # Extracting the links within each of the 'result-link' elements\n",
    "        #     links = []\n",
    "        #     for element in result_link_elements:\n",
    "        #         print(element)\n",
    "        #         print(type(element))\n",
    "        #         link = element.get_attribute('href')\n",
    "        #         print(link)\n",
    "        #         links.append(link)\n",
    "\n",
    "        \n",
    "        # return links\n",
    "\n",
    "\n",
    "    def search_anwser(self,link):\n",
    "        answer = dict()\n",
    "        title_XPATH = '//*[@id=\"question-header\"]/h1/a'\n",
    "        answer_body_CLASS = 's-prose js-post-body'\n",
    "        self.driver.get(link)\n",
    "        title = self._wait(By.XPATH, title_XPATH)\n",
    "\n",
    "        answer_body = self._wait(By.CLASS_NAME, answer_body_CLASS)\n",
    "\n",
    "        answer['title'] = title.text\n",
    "        answer['answer'] = answer_body.text\n",
    "\n",
    "        return answer\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def scrape(self, input):\n",
    "        \"\"\"\n",
    "        Main method to scrape StackExchange for a given query and return the texts in a list.\n",
    "        \"\"\"\n",
    "        #self._setup_headless_driver()\n",
    "        \n",
    "        elements = self.search_links(input)\n",
    "        #texts = [i.herf for i in elements if i.herf != '']\n",
    "        #time.sleep(10)\n",
    "        self.driver.quit()\n",
    "\n",
    "        return elements\n",
    "\n",
    "# Note: As before, the Selenium portion cannot be executed in this environment. \n",
    "# The code should be run in a local environment with the appropriate browser driver.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "SS = StackExchangeScraper(chrome_driver_path=max_chrome_driver_path,username=username, password=password)\n",
    "content =SS.scrape('what is negative matter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'WebElement' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(result, parser\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m links \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mtext\n\u001b[1;32m      3\u001b[0m links \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bs4/__init__.py:313\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(markup, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):        \u001b[39m# It's a file-type object.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     markup \u001b[39m=\u001b[39m markup\u001b[39m.\u001b[39mread()\n\u001b[0;32m--> 313\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39;49m(markup) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m256\u001b[39m \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    314\u001b[0m         (\u001b[39misinstance\u001b[39m(markup, \u001b[39mbytes\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m markup)\n\u001b[1;32m    315\u001b[0m         \u001b[39mor\u001b[39;00m (\u001b[39misinstance\u001b[39m(markup, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m markup)\n\u001b[1;32m    316\u001b[0m ):\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Issue warnings for a couple beginner problems\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39m# involving passing non-markup to Beautiful Soup.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[39m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_markup_is_url(markup):\n\u001b[1;32m    322\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_markup_resembles_filename(markup)                \n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'WebElement' has no len()"
     ]
    }
   ],
   "source": [
    "\n",
    "soup = BeautifulSoup(content, parser='html.parser')\n",
    "#links = content.text\n",
    "links = soup.find_all('a')\n",
    "herfs = []\n",
    "for link in links:\n",
    "    herf = link.get('herf')\n",
    "    herfs.append(herf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "herfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(parser\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m, content\u001b[39m=\u001b[39;49mresult)\n\u001b[1;32m      2\u001b[0m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mherf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bs4/__init__.py:257\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39m# with the remaining **kwargs.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39mif\u001b[39;00m builder \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m     builder \u001b[39m=\u001b[39m builder_class(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    258\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m original_builder \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (\n\u001b[1;32m    259\u001b[0m             original_features \u001b[39m==\u001b[39m builder\u001b[39m.\u001b[39mNAME \u001b[39mor\u001b[39;00m\n\u001b[1;32m    260\u001b[0m             original_features \u001b[39min\u001b[39;00m builder\u001b[39m.\u001b[39mALTERNATE_NAMES\n\u001b[1;32m    261\u001b[0m     ) \u001b[39mand\u001b[39;00m markup:\n\u001b[1;32m    262\u001b[0m         \u001b[39m# The user did not tell us which TreeBuilder to use,\u001b[39;00m\n\u001b[1;32m    263\u001b[0m         \u001b[39m# and we had to guess. Issue a warning.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m         \u001b[39mif\u001b[39;00m builder\u001b[39m.\u001b[39mis_xml:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/bs4/builder/_lxml.py:139\u001b[0m, in \u001b[0;36mLXMLTreeBuilderForXML.__init__\u001b[0;34m(self, parser, empty_element_tags, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnsmaps \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_NSMAPS_INVERTED]\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactive_namespace_prefixes \u001b[39m=\u001b[39m [\u001b[39mdict\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mDEFAULT_NSMAPS)]\n\u001b[0;32m--> 139\u001b[0m \u001b[39msuper\u001b[39;49m(LXMLTreeBuilderForXML, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'content'"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(parser='html.parser', content=result)\n",
    "soup.find_all('herf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_execute',\n",
       " '_id',\n",
       " '_parent',\n",
       " '_upload',\n",
       " 'accessible_name',\n",
       " 'aria_role',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'find_element',\n",
       " 'find_elements',\n",
       " 'get_attribute',\n",
       " 'get_dom_attribute',\n",
       " 'get_property',\n",
       " 'id',\n",
       " 'is_displayed',\n",
       " 'is_enabled',\n",
       " 'is_selected',\n",
       " 'location',\n",
       " 'location_once_scrolled_into_view',\n",
       " 'parent',\n",
       " 'rect',\n",
       " 'screenshot',\n",
       " 'screenshot_as_base64',\n",
       " 'screenshot_as_png',\n",
       " 'send_keys',\n",
       " 'shadow_root',\n",
       " 'size',\n",
       " 'submit',\n",
       " 'tag_name',\n",
       " 'text',\n",
       " 'value_of_css_property']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
